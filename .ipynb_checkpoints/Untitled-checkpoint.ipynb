{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772013c9-3491-4f35-b1f5-600f641fca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c231d-a51d-4552-b952-bad6c3f0c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_my_dataset(data_dir, train_ratio=0.8):\n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "    num_classes = len(class_names)\n",
    "    x, y = [], []\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for img_filename in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            x.append(img)\n",
    "            y.append(class_idx)\n",
    "\n",
    "    x = np.array(x, dtype='uint8')\n",
    "    y = np.array(y, dtype='uint8')\n",
    "    \n",
    "    num_samples = len(y)\n",
    "    if num_samples == 0:\n",
    "        raise ValueError('No samples found in data directory')\n",
    "    \n",
    "    if not 0 <= train_ratio <= 1:\n",
    "        raise ValueError('Invalid value for train_ratio')\n",
    "    \n",
    "    num_train_samples = int(num_samples * train_ratio)\n",
    "    if num_train_samples == 0:\n",
    "        raise ValueError('No samples found for training set')\n",
    "    elif num_train_samples == num_samples:\n",
    "        raise ValueError('All samples used for training set')\n",
    "    \n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    \n",
    "    x_train, y_train = x[:num_train_samples], y[:num_train_samples]\n",
    "    x_test, y_test = x[num_train_samples:], y[num_train_samples:]\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "    \n",
    "    x_train = x_train.transpose(0, 1, 2, 3) # channels first format\n",
    "    x_test = x_test.transpose(0, 1, 2, 3) # channels first format\n",
    "    \n",
    "    x_train = x_train.astype('uint8')\n",
    "    y_train = y_train.astype('uint8')\n",
    "    x_test = x_test.astype('uint8')\n",
    "    y_test = y_test.astype('uint8')\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e9f02-be1c-469e-a267-f03407cd9853",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dataAll/'\n",
    "(X_train, y_train), (X_test, y_test) = load_my_dataset(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996657af-7cd1-40aa-8d98-83859eaefb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((X_train[0], y_train[0]))\n",
    "print(X_train.dtype, y_train.dtype, X_test.dtype, y_test.dtype)\n",
    "# print((X_test[0], y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4aee1-d42c-4e87-bb6b-75ff18725c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed284e-289c-4474-acd9-46b2b08297bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773bffe-cd31-4ed9-8059-c8759b8f13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e0f3d4-c218-4f21-a0b6-0cc8bee2ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1f78a-3ee4-40b5-84ef-6ad283f0910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65fd64-dd7a-47b1-8849-ce0594648372",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1,)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdebf87-9720-4674-a494-b3d19eecaeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621046b0-dfd2-44bb-afc7-aefe2f8e612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['0','33','66','Full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d556da72-6135-429c-a2d1-75fcf9687802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X,y, index):\n",
    "    plt.figure(figsize=(15,2))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel(classes[y[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee9331-7905-42de-b719-59f8653ebfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(X_train, y_train, 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2d3b5-569a-47d5-b6f4-17d6a9c8db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "print(X_train[0], X_test[0],y_train[0],y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e1071b-38b7-4f85-a107-3e97d13fc3c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### This training does not work on pixel 244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0955b612-53d2-4a7d-815b-002beada24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = models.Sequential([\n",
    "    layers.Flatten(input_shape=(224,224,3)),\n",
    "    layers.Dense(3000,activation='relu'),\n",
    "    layers.Dense(1000,activation='relu'),\n",
    "    layers.Dense(10, activation ='softmax')\n",
    "])\n",
    "\n",
    "ann.compile(optimizer ='SGD',\n",
    "           loss ='sparse_categorical_crossentropy',\n",
    "           metrics=['accuracy'])\n",
    "\n",
    "ann.fit(X_train, y_train, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723bc262-f7ac-46d6-9c77-f35cf9cd2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60665dff-0f1e-43ad-8521-d252c86a7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "y_pred = ann.predict(X_test)  # Get predicted probabilities\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "# print(X_test[:5])\n",
    "# print(y_test[:10])\n",
    "# print(y_pred_classes.dtype)\n",
    "# print(y_pred)\n",
    "# print(y_pred_classes)\n",
    "print('Classification Report:', classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0505e3e1-0ecb-47cb-aacc-bd1c1194d97f",
   "metadata": {},
   "source": [
    "#### The code below is for traning pictures 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67f56b-6447-4bb8-920c-7f3cae954193",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters = 16, kernel_size = (3,3), activation = 'relu', input_shape =(224,224,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde861f-7f5d-4f8a-ba6b-61ffdc81382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10691fa0-c65c-4f04-bedd-5dfc1052a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(X_train, y_train, epochs = 3)\n",
    "# cnn.fit(partial_images, partial_labels, batch_size=32,\n",
    "#                     epochs=25, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc88c0-fc73-4803-a06c-efc0d1f29de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23bd36e-a8e1-4828-bdda-216c2a5b426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c08bd9-97a4-4641-8ba5-91ba446f2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421d725-9e93-4482-b253-46409d448706",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(X_test, y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ef901-0260-42de-842a-3941e9e882e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55508d-e857-41fa-b77a-1dd4d97ea1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d2187-3fa1-4859-82cb-6dabe34629e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fc760-dff0-4932-9645-6f96a4f2dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "num = random.randint(0,624)\n",
    "plot_sample(X_test, y_test, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179650b6-368f-4120-9bf8-0a25a1090f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[y_classes[num]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7903198-9999-485c-91b0-a4f4281a1dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print('classification report : \\n', classification_report(y_test, y_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58bcbcc-5c06-4f31-8793-046f872304b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(\"manualTrain224.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a57725-42c2-4e2d-9cfe-3e17ca73e5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
